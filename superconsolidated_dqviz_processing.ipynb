{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# List of file names\n",
    "file_names = [\n",
    "    \"010224_ALL_VAX.xlsx\", \"010924_ALL_VAX.xlsx\", \"011624_ALL_VAX.xlsx\",\n",
    "    \"012224_ALL_VAX.xlsx\", \"012924_ALL_VAX.xlsx\", \"020524_ALL_VAX.xlsx\",\n",
    "    \"021224_ALL_VAX.xlsx\", \"022024_ALL_VAX.xlsx\", \"022624_ALL_VAX.xlsx\",\n",
    "    \"030424_ALL_VAX.xlsx\", \"031124_ALL_VAX.xlsx\", \"031824_ALL_VAX.xlsx\",\n",
    "    \"032524_ALL_VAX.xlsx\", \"040124_ALL_VAX.xlsx\", \"040824_ALL_VAX.xlsx\",\n",
    "    \"041524_ALL_VAX.xlsx\", \"042224_ALL_VAX.xlsx\", \"042924_ALL_VAX.xlsx\",\n",
    "    \"ALL_VAX_2024-05-08.xlsx\", \"ALL_VAX_2024-05-13.xlsx\", \"ALL_VAX_2024-05-20.xlsx\",\n",
    "    \"ALL_VAX_2024-05-27.xlsx\"\n",
    "]\n",
    "\n",
    "# Load all weeks into a list\n",
    "weeks = [pd.read_excel(file) for file in file_names]\n",
    "\n",
    "# Fill NaN values with 0\n",
    "for week in weeks:\n",
    "    week.fillna(0, inplace=True)\n",
    "\n",
    "week_dates = [\n",
    "    '01-02-24', '01-09-24', '01-16-24', '01-22-24', '01-29-24', '02-05-24',\n",
    "    '02-12-24', '02-20-24', '02-26-24', '03-04-24', '03-11-24', '03-18-24',\n",
    "    '03-25-24', '04-01-24', '04-08-24', '04-15-24', '04-22-24', '04-29-24',\n",
    "    '05-06-24', '05-13-24', '05-20-24', '05-27-24'\n",
    "]\n",
    "\n",
    "# Function to process weeks data\n",
    "def process_weeks(weeks, week_dates, column_name):\n",
    "    top_15_list = []\n",
    "    top_16_to_100_list = []\n",
    "\n",
    "    for week, date in zip(weeks, week_dates):\n",
    "        week_copy = week[['PROVIDER_NAME', column_name]].copy()\n",
    "        \n",
    "        # Top 15\n",
    "        top_15 = week_copy.sort_values(by=column_name, ascending=False).head(15)\n",
    "        top_15['Week'] = date\n",
    "        top_15.reset_index(drop=True, inplace=True)\n",
    "        top_15_list.append(top_15)\n",
    "        \n",
    "        # Top 16-100\n",
    "        top_16_to_100 = week_copy.sort_values(by=column_name, ascending=False).iloc[15:]\n",
    "        top_16_to_100['Week'] = date\n",
    "        top_16_to_100.reset_index(drop=True, inplace=True)\n",
    "        top_16_to_100_list.append(top_16_to_100)\n",
    "\n",
    "    return pd.concat(top_15_list, ignore_index=True), pd.concat(top_16_to_100_list, ignore_index=True)\n",
    "\n",
    "# Process for different columns\n",
    "columns_to_process = ['HL7_TOTAL_COUNT_8_DAYS', 'HL7_ETHNICITY_COUNT_8_DAYS', 'UNKNOWN_GENDER', 'SHOT_ADMIN_DATE_ON_DOB']\n",
    "\n",
    "for column in columns_to_process:\n",
    "    top_15_df, top_16_to_100_df = process_weeks(weeks, week_dates, column)\n",
    "\n",
    "    # Left join on top 15 providers with 16-100 to fill the gaps when the top 15 is empty\n",
    "    top15_left_df = pd.merge(top_15_df, top_16_to_100_df, on='PROVIDER_NAME', how='left')\n",
    "    \n",
    "    top15_left_hl7 = pd.melt(\n",
    "        top15_left_df,\n",
    "        id_vars=['PROVIDER_NAME'],\n",
    "        value_vars=[f'{column}_x', f'{column}_y'],\n",
    "        var_name=column,\n",
    "        value_name=f'{column}_value'\n",
    "    )\n",
    "    \n",
    "    # Melt the DataFrame to combine 'Week_x' and 'Week_y' into one column called 'Week'\n",
    "    top_15_left_week = pd.melt(\n",
    "        top15_left_df,\n",
    "        id_vars=['PROVIDER_NAME'],\n",
    "        value_vars=['Week_x', 'Week_y'],\n",
    "        var_name='Week',\n",
    "        value_name='Week_value'\n",
    "    )\n",
    "    \n",
    "    # Replace 'HL7_TOTAL_8DAYS' with 'HL7_TOTAL_8DAYS_value'\n",
    "    top15_left_hl7[column] = top15_left_hl7[f'{column}_value']\n",
    "    top15_left_hl7.drop(columns=[f'{column}_value'], inplace=True)\n",
    "    \n",
    "    # Replace 'Week' values with 'Week_value'\n",
    "    top_15_left_week['Week'] = top_15_left_week['Week_value']\n",
    "    top_15_left_week.drop(columns=['Week_value'], inplace=True)\n",
    "    \n",
    "    # Concatenate two dataframes\n",
    "    tmp_df = pd.concat([top15_left_hl7[['PROVIDER_NAME', column]], top_15_left_week['Week']], axis=1)\n",
    "    tmp_df_nodup = tmp_df.drop_duplicates()\n",
    "    \n",
    "    # Save to Excel\n",
    "    tmp_df_nodup.to_excel(f\"top15_{column}_052924-super-consolidated_code.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
